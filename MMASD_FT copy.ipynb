{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14463,
     "status": "ok",
     "timestamp": 1764045990680,
     "user": {
      "displayName": "Aurora Cao",
      "userId": "01537032954294902123"
     },
     "user_tz": -480
    },
    "id": "c-Kp3XYt2GrF",
    "outputId": "8e9f06d2-1279-4adb-d070-57c027d860df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备：cuda\n",
      "GPU型号：NVIDIA L20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 中文显示配置（兼容英文环境）\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备：{device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU型号：{torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ========== 核心参数配置 ==========\n",
    "PKL_3D_DIR = '/root/second/3D'  # 你的3D骨架数据路径\n",
    "TARGET_FRAMES = 32  # 统一帧长\n",
    "BATCH_SIZE = 8\n",
    "PRETRAIN_EPOCHS = 20  # 预训练轮数\n",
    "FINETUNE_EPOCHS = 30  # 微调轮数\n",
    "ANOMALY_THRESHOLD = 0.8\n",
    "NUM_JOINTS = 71\n",
    "PRETRAIN_LR = 1e-4    # 预训练学习率\n",
    "FINETUNE_LR = 1e-5    # 微调学习率（更小）\n",
    "\n",
    "# 模型超参数\n",
    "D_MODEL = 64       # 特征维度\n",
    "NHEAD = 8          # 注意力头数\n",
    "NUM_LAYERS = 2     # Transformer层数\n",
    "DROPOUT = 0.2      # Dropout率\n",
    "\n",
    "# 动作组定义（按类型聚类）\n",
    "ACTION_GROUPS = {\n",
    "    \"group_swing_squat\": [\"arm_swing_as\", \"body_swing_bs\", \"chest_expansion_ce\", \"squat_sq\"],\n",
    "    \"group_drumming_shaking\": [\"drumming_dr\", \"maracas_forward_shaking_mfs\", \"maracas_shaking_ms\", \"sing_and_clap_sac\"],\n",
    "    \"group_pose\": [\"frog_pose_fg\", \"tree_pose_tr\", \"twist_pose_tw\"]\n",
    "}\n",
    "THEME_TO_GROUP = {theme: group_name \n",
    "                 for group_name, themes in ACTION_GROUPS.items() \n",
    "                 for theme in themes}\n",
    "\n",
    "# ========== 保存路径配置（分层目录） ==========\n",
    "BASE_OUTPUT_DIR = 'st_transformer_action_ft_results'  # 基础输出目录\n",
    "PRETRAIN_DIR = os.path.join(BASE_OUTPUT_DIR, 'pretrain_model')  # 预训练模型目录\n",
    "FINETUNE_DIR = os.path.join(BASE_OUTPUT_DIR, 'finetune_models')  # 微调模型目录\n",
    "VISUALIZATION_DIR = os.path.join(BASE_OUTPUT_DIR, 'visualizations')  # 可视化结果目录\n",
    "RESULTS_DIR = os.path.join(BASE_OUTPUT_DIR, 'detection_results')  # 检测结果目录\n",
    "\n",
    "# 创建目录（不存在则创建）\n",
    "for dir_path in [BASE_OUTPUT_DIR, PRETRAIN_DIR, FINETUNE_DIR, VISUALIZATION_DIR, RESULTS_DIR]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "# 预训练模型路径（指定文件名）\n",
    "PRETRAIN_MODEL_PATH = os.path.join(PRETRAIN_DIR, 'drumming_shaking_pretrain_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2477,
     "status": "ok",
     "timestamp": 1764044494400,
     "user": {
      "displayName": "Aurora Cao",
      "userId": "01537032954294902123"
     },
     "user_tz": -480
    },
    "id": "eOHH5Al4L8I3",
    "outputId": "4fda6f96-a3ac-4e61-f64e-a6950a78aa51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 11 个pkl文件，按组加载...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "加载数据: 100%|██████████| 11/11 [00:00<00:00, 172.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据加载完成：\n",
      "- 预训练组（group_drumming_shaking）：712训练样本，179测试样本\n",
      "- 微调组（group_swing_squat）：352训练样本，88测试样本\n",
      "- 微调组（group_pose）：289训练样本，73测试样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========== 数据集类 ==========\n",
    "class SkeletonDataset(Dataset):\n",
    "    \"\"\"骨架数据集（支持组内归一化和帧长统一）\"\"\"\n",
    "    def __init__(self, sequences, file_names, mean=None, std=None, is_train=True):\n",
    "        self.sequences = sequences  # (N, T, J, C)\n",
    "        self.file_names = file_names\n",
    "        self.is_train = is_train\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "        # 训练集计算全局归一化统计量\n",
    "        if self.is_train:\n",
    "            self.mean = np.mean(self.sequences, axis=(0, 1), keepdims=True)  # (1,1,J,C)\n",
    "            self.std = np.std(self.sequences, axis=(0, 1), keepdims=True) + 1e-6  # 避免除零\n",
    "        \n",
    "        # 数据归一化\n",
    "        self.sequences_norm = (self.sequences - self.mean) / self.std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sequences_norm[idx], dtype=torch.float32)\n",
    "    \n",
    "    def get_original_data(self, idx):\n",
    "        \"\"\"获取原始数据（非归一化）\"\"\"\n",
    "        return self.sequences[idx], self.file_names[idx]\n",
    "\n",
    "# ========== 数据加载函数（单独提取第二组） ==========\n",
    "def load_data_by_group(root_dir, target_frames=32):\n",
    "    \"\"\"加载所有组数据，并单独返回第二组（数据量大的组）\"\"\"\n",
    "    group_data = {\n",
    "        \"group_swing_squat\": {\"sequences\": [], \"file_names\": []},\n",
    "        \"group_drumming_shaking\": {\"sequences\": [], \"file_names\": []},\n",
    "        \"group_pose\": {\"sequences\": [], \"file_names\": []}\n",
    "    }\n",
    "    \n",
    "    # 遍历所有PKL文件\n",
    "    pkl_files = []\n",
    "    for root, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.pkl'):\n",
    "                pkl_files.append(os.path.join(root, file))\n",
    "    \n",
    "    print(f\"找到 {len(pkl_files)} 个pkl文件，按组加载...\")\n",
    "    \n",
    "    for pkl_path in tqdm(pkl_files, desc=\"加载数据\"):\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # 过滤3D模态\n",
    "        metadata = data['metadata']\n",
    "        if metadata['data_type'].split('_')[-1] != '3d':\n",
    "            continue\n",
    "        \n",
    "        # 匹配动作组\n",
    "        theme_name = metadata['theme_name']\n",
    "        if theme_name in [\"arm_swing_as\", \"body_swing_bs\", \"chest_expansion_ce\", \"squat_sq\"]:\n",
    "            group_name = \"group_swing_squat\"\n",
    "        elif theme_name in [\"drumming_dr\", \"maracas_forward_shaking_mfs\", \"maracas_shaking_ms\", \"sing_and_clap_sac\"]:\n",
    "            group_name = \"group_drumming_shaking\"  # 第二组（数据量大）\n",
    "        elif theme_name in [\"frog_pose_fg\", \"tree_pose_tr\", \"twist_pose_tw\"]:\n",
    "            group_name = \"group_pose\"\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # 处理每个样本的帧长统一\n",
    "        samples = data['samples']\n",
    "        for sample in samples:\n",
    "            skeleton = sample['skeleton_3d']  # (T, J, C)\n",
    "            T = skeleton.shape[0]\n",
    "            \n",
    "            # 帧长统一为target_frames\n",
    "            if T > target_frames:\n",
    "                indices = np.linspace(0, T-1, target_frames, dtype=int)\n",
    "                skeleton_unified = skeleton[indices]\n",
    "            else:\n",
    "                indices = np.linspace(0, T-1, target_frames)\n",
    "                skeleton_unified = np.zeros((target_frames, NUM_JOINTS, 3))\n",
    "                for j in range(NUM_JOINTS):\n",
    "                    for c in range(3):\n",
    "                        skeleton_unified[:, j, c] = np.interp(indices, np.arange(T), skeleton[:, j, c])\n",
    "            \n",
    "            group_data[group_name][\"sequences\"].append(skeleton_unified)\n",
    "            group_data[group_name][\"file_names\"].append(f\"{os.path.basename(pkl_path)}_{theme_name}\")\n",
    "    \n",
    "    # 为每个组划分训练/测试集（8:2）\n",
    "    group_datasets = {}\n",
    "    for group_name, data in group_data.items():\n",
    "        sequences = np.array(data[\"sequences\"], dtype=np.float32)\n",
    "        file_names = data[\"file_names\"]\n",
    "        \n",
    "        # 划分训练/测试集\n",
    "        train_size = int(0.8 * len(sequences))\n",
    "        test_size = len(sequences) - train_size\n",
    "        train_seq, test_seq = sequences[:train_size], sequences[train_size:]\n",
    "        train_names, test_names = file_names[:train_size], file_names[train_size:]\n",
    "        \n",
    "        # 创建Dataset\n",
    "        train_dataset = SkeletonDataset(train_seq, train_names, is_train=True)\n",
    "        test_dataset = SkeletonDataset(test_seq, test_names, mean=train_dataset.mean, std=train_dataset.std, is_train=False)\n",
    "        \n",
    "        # 创建DataLoader\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        group_datasets[group_name] = {\n",
    "            \"train_dataset\": train_dataset,\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"train_loader\": train_loader,\n",
    "            \"test_loader\": test_loader,\n",
    "            \"mean\": train_dataset.mean,\n",
    "            \"std\": train_dataset.std\n",
    "        }\n",
    "    \n",
    "    # 单独提取第二组（预训练用）\n",
    "    pretrain_group = \"group_drumming_shaking\"\n",
    "    pretrain_data = {\n",
    "        \"train_loader\": group_datasets[pretrain_group][\"train_loader\"],\n",
    "        \"test_loader\": group_datasets[pretrain_group][\"test_loader\"],\n",
    "        \"mean\": group_datasets[pretrain_group][\"mean\"],\n",
    "        \"std\": group_datasets[pretrain_group][\"std\"]\n",
    "    }\n",
    "    \n",
    "    # 待微调的组（另外两个组）\n",
    "    finetune_groups = {k: v for k, v in group_datasets.items() if k != pretrain_group}\n",
    "    \n",
    "    print(f\"\\n数据加载完成：\")\n",
    "    print(f\"- 预训练组（{pretrain_group}）：{len(group_datasets[pretrain_group]['train_dataset'])}训练样本，{len(group_datasets[pretrain_group]['test_dataset'])}测试样本\")\n",
    "    for group_name, data in finetune_groups.items():\n",
    "        print(f\"- 微调组（{group_name}）：{len(data['train_dataset'])}训练样本，{len(data['test_dataset'])}测试样本\")\n",
    "    \n",
    "    return pretrain_data, finetune_groups\n",
    "\n",
    "# ========== 执行数据加载 ==========\n",
    "pretrain_data, finetune_groups = load_data_by_group(PKL_3D_DIR, TARGET_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "B2pL8zYohef_"
   },
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"空间注意力层：捕捉单帧内关节间依赖\"\"\"\n",
    "    def __init__(self, d_model, nhead=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model * 4, d_model)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, J, d = x.shape\n",
    "        x_reshaped = rearrange(x, 'b t j d -> (b t) j d')  # (B*T, J, d)\n",
    "        \n",
    "        # 自注意力+残差连接\n",
    "        attn_out, _ = self.self_attn(x_reshaped, x_reshaped, x_reshaped)\n",
    "        x_reshaped = x_reshaped + self.dropout1(attn_out)\n",
    "        x_reshaped = self.norm1(x_reshaped)\n",
    "        \n",
    "        # 前馈网络+残差连接\n",
    "        ffn_out = self.ffn(x_reshaped)\n",
    "        x_reshaped = x_reshaped + self.dropout2(ffn_out)\n",
    "        x_reshaped = self.norm2(x_reshaped)\n",
    "        \n",
    "        return rearrange(x_reshaped, '(b t) j d -> b t j d', b=B, t=T)\n",
    "\n",
    "class TemporalAttention(nn.Module):\n",
    "    \"\"\"时间注意力层：捕捉帧间时序依赖\"\"\"\n",
    "    def __init__(self, d_model, nhead=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model * 4, d_model)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, J, d = x.shape\n",
    "        x_reshaped = rearrange(x, 'b t j d -> (b j) t d')  # (B*J, T, d)\n",
    "        \n",
    "        # 自注意力+残差连接\n",
    "        attn_out, _ = self.self_attn(x_reshaped, x_reshaped, x_reshaped)\n",
    "        x_reshaped = x_reshaped + self.dropout1(attn_out)\n",
    "        x_reshaped = self.norm1(x_reshaped)\n",
    "        \n",
    "        # 前馈网络+残差连接\n",
    "        ffn_out = self.ffn(x_reshaped)\n",
    "        x_reshaped = x_reshaped + self.dropout2(ffn_out)\n",
    "        x_reshaped = self.norm2(x_reshaped)\n",
    "        \n",
    "        return rearrange(x_reshaped, '(b j) t d -> b t j d', b=B, j=J)\n",
    "\n",
    "class STTransformerBlock(nn.Module):\n",
    "    \"\"\"时空Transformer块（空间+时间注意力）\"\"\"\n",
    "    def __init__(self, d_model, nhead=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.spatial_attn = SpatialAttention(d_model, nhead, dropout)\n",
    "        self.temporal_attn = TemporalAttention(d_model, nhead, dropout)\n",
    "        self.residual_proj = nn.Linear(d_model, d_model)  # 残差投影\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 空间注意力+残差\n",
    "        spatial_out = self.spatial_attn(x)\n",
    "        x = x + self.residual_proj(spatial_out)\n",
    "        \n",
    "        # 时间注意力+残差\n",
    "        temporal_out = self.temporal_attn(x)\n",
    "        x = x + self.residual_proj(temporal_out)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class STTransformerAutoencoder(nn.Module):\n",
    "    \"\"\"完整的ST-Transformer自编码器\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 输入投影：(B, T, J, 3) → (B, T, J, D_MODEL)\n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.Linear(3, D_MODEL),\n",
    "            nn.LayerNorm(D_MODEL),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(DROPOUT)\n",
    "        )\n",
    "        \n",
    "        # 编码器（堆叠时空Transformer块）\n",
    "        self.encoder = nn.Sequential(*[\n",
    "            STTransformerBlock(D_MODEL, NHEAD, DROPOUT) for _ in range(NUM_LAYERS)\n",
    "        ])\n",
    "        \n",
    "        # 解码器（堆叠时空Transformer块）\n",
    "        self.decoder = nn.Sequential(*[\n",
    "            STTransformerBlock(D_MODEL, NHEAD, DROPOUT) for _ in range(NUM_LAYERS)\n",
    "        ])\n",
    "        \n",
    "        # 输出投影：(B, T, J, D_MODEL) → (B, T, J, 3)\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.Linear(D_MODEL, D_MODEL // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(DROPOUT),\n",
    "            nn.Linear(D_MODEL // 2, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入投影\n",
    "        x = self.input_proj(x)\n",
    "        # 编码\n",
    "        z = self.encoder(x)\n",
    "        # 解码\n",
    "        x_recon = self.decoder(z)\n",
    "        # 输出投影\n",
    "        x_recon = self.output_proj(x_recon)\n",
    "        return x_recon\n",
    "\n",
    "    def get_reconstruction_error(self, x):\n",
    "        \"\"\"计算帧级/序列级异常概率（0-1）\"\"\"\n",
    "        with torch.no_grad():\n",
    "            x_recon = self.forward(x)\n",
    "            # 帧级MSE误差：(B, T)\n",
    "            frame_errors = torch.mean((x - x_recon) ** 2, dim=[2, 3])\n",
    "        \n",
    "        # 归一化到0-1区间\n",
    "        frame_errors_np = frame_errors.cpu().numpy()\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        frame_probs = np.zeros_like(frame_errors_np)\n",
    "        \n",
    "        for i in range(frame_errors_np.shape[0]):\n",
    "            frame_probs[i] = scaler.fit_transform(frame_errors_np[i].reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # 序列级异常概率（帧概率均值）\n",
    "        seq_probs = np.mean(frame_probs, axis=1)\n",
    "        return seq_probs, frame_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1437621,
     "status": "ok",
     "timestamp": 1764045939406,
     "user": {
      "displayName": "Aurora Cao",
      "userId": "01537032954294902123"
     },
     "user_tz": -480
    },
    "id": "E2k76vUXTG70",
    "outputId": "136f9146-d9bf-4941-9708-ad4650c4903c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始用第二组（group_drumming_shaking）预训练（20轮）...\n",
      "================================================================================\n",
      "Epoch Train Loss   Val Loss     Train Acc    Val Acc     \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1:  13%|█▎        | 12/89 [00:00<00:02, 34.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1: 100%|██████████| 89/89 [00:02<00:00, 34.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     0.340131     0.026791     0.8948       0.9153      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2: 100%|██████████| 89/89 [00:02<00:00, 34.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2     0.141141     0.013456     0.9108       0.9269      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3: 100%|██████████| 89/89 [00:02<00:00, 34.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3     0.115191     0.011242     0.9113       0.9213      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4: 100%|██████████| 89/89 [00:02<00:00, 34.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4     0.102244     0.009490     0.9161       0.9232      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5: 100%|██████████| 89/89 [00:02<00:00, 34.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5     0.094025     0.008556     0.9136       0.9253      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 6: 100%|██████████| 89/89 [00:02<00:00, 35.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6     0.088369     0.008001     0.9149       0.9267      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 7: 100%|██████████| 89/89 [00:02<00:00, 35.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7     0.084134     0.008373     0.9159       0.9328      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 8: 100%|██████████| 89/89 [00:02<00:00, 35.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8     0.081073     0.007779     0.9134       0.9323      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 9: 100%|██████████| 89/89 [00:02<00:00, 35.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9     0.078602     0.007393     0.9143       0.9331      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 10: 100%|██████████| 89/89 [00:02<00:00, 34.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10    0.076759     0.007219     0.9138       0.9347      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 11: 100%|██████████| 89/89 [00:02<00:00, 34.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    0.075262     0.007183     0.9166       0.9293      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 12: 100%|██████████| 89/89 [00:02<00:00, 34.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12    0.074204     0.006994     0.9139       0.9323      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 13: 100%|██████████| 89/89 [00:02<00:00, 34.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13    0.073344     0.006742     0.9140       0.9298      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 14: 100%|██████████| 89/89 [00:02<00:00, 34.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14    0.072618     0.006421     0.9102       0.9319      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 15: 100%|██████████| 89/89 [00:02<00:00, 34.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    0.072088     0.006294     0.9149       0.9314      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 16: 100%|██████████| 89/89 [00:02<00:00, 34.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    0.071632     0.006260     0.9157       0.9303      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 17: 100%|██████████| 89/89 [00:02<00:00, 34.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    0.071312     0.006271     0.9116       0.9302      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 18: 100%|██████████| 89/89 [00:02<00:00, 35.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    0.071140     0.006311     0.9152       0.9300      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 19: 100%|██████████| 89/89 [00:02<00:00, 35.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    0.071014     0.006387     0.9153       0.9293      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 20: 100%|██████████| 89/89 [00:02<00:00, 35.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20    0.071016     0.006376     0.9138       0.9288      \n",
      "\n",
      "预训练完成！最优验证损失：0.006260 | 最优验证准确率：0.9303\n",
      "预训练模型保存路径：st_transformer_action_ft_results/pretrain_model/drumming_shaking_pretrain_best.pth\n",
      "\n",
      "========== 开始微调 group_swing_squat ==========\n",
      "\n",
      "开始微调 group_swing_squat（30轮）...\n",
      "================================================================================\n",
      "Epoch Train Loss   Val Loss     Train Acc    Val Acc     \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102041/1041620738.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrain_ckpt = torch.load(pretrain_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     0.088423     0.017962     0.9108       0.8867      \n",
      "2     0.085985     0.017417     0.9136       0.8899      \n",
      "3     0.084925     0.016351     0.9116       0.8917      \n",
      "4     0.083670     0.015926     0.9175       0.8931      \n",
      "5     0.083069     0.014074     0.9117       0.8945      \n",
      "6     0.082419     0.014080     0.9139       0.8945      \n",
      "7     0.081780     0.013966     0.9129       0.8945      \n",
      "8     0.081358     0.013250     0.9099       0.8952      \n",
      "9     0.081060     0.012913     0.9120       0.8952      \n",
      "10    0.080567     0.012067     0.9086       0.8970      \n",
      "11    0.080062     0.013342     0.9118       0.8931      \n",
      "12    0.079943     0.012675     0.9126       0.8956      \n",
      "13    0.079726     0.012505     0.9144       0.8956      \n",
      "14    0.079561     0.011523     0.9167       0.8999      \n",
      "15    0.079309     0.011525     0.9103       0.8984      \n",
      "16    0.079070     0.011617     0.9094       0.8988      \n",
      "17    0.078956     0.011631     0.9076       0.8974      \n",
      "18    0.078612     0.011312     0.9144       0.8999      \n",
      "19    0.078600     0.011673     0.9092       0.8981      \n",
      "20    0.078750     0.011523     0.9098       0.8970      \n",
      "21    0.078497     0.011388     0.9097       0.8991      \n",
      "22    0.078371     0.011236     0.9121       0.8988      \n",
      "23    0.078261     0.011451     0.9162       0.8974      \n",
      "24    0.078720     0.011225     0.9120       0.8981      \n",
      "25    0.078068     0.011274     0.9110       0.8981      \n",
      "26    0.078187     0.011217     0.9099       0.8981      \n",
      "27    0.078299     0.011261     0.9123       0.8977      \n",
      "28    0.078391     0.011264     0.9113       0.8977      \n",
      "29    0.078207     0.011263     0.9097       0.8977      \n",
      "30    0.078134     0.011258     0.9129       0.8977      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 25439 (\\N{CJK UNIFIED IDEOGRAPH-635F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 35757 (\\N{CJK UNIFIED IDEOGRAPH-8BAD}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 32451 (\\N{CJK UNIFIED IDEOGRAPH-7EC3}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 35777 (\\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 25439 (\\N{CJK UNIFIED IDEOGRAPH-635F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 35757 (\\N{CJK UNIFIED IDEOGRAPH-8BAD}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 32451 (\\N{CJK UNIFIED IDEOGRAPH-7EC3}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 35777 (\\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练曲线保存路径：st_transformer_action_ft_results/visualizations/group_swing_squat_training_curves.png\n",
      "\n",
      "group_swing_squat 微调完成！最优验证损失：0.011217 | 最优验证准确率：0.8981\n",
      "微调模型保存路径：st_transformer_action_ft_results/finetune_models/group_swing_squat_finetuned_best.pth\n",
      "\n",
      "========== 开始微调 group_pose ==========\n",
      "\n",
      "开始微调 group_pose（30轮）...\n",
      "================================================================================\n",
      "Epoch Train Loss   Val Loss     Train Acc    Val Acc     \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102041/1041620738.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrain_ckpt = torch.load(pretrain_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     0.075439     0.015927     0.9189       0.9247      \n",
      "2     0.074924     0.015189     0.9181       0.9264      \n",
      "3     0.074207     0.014564     0.9154       0.9247      \n",
      "4     0.074294     0.014610     0.9147       0.9272      \n",
      "5     0.073734     0.014629     0.9168       0.9255      \n",
      "6     0.073676     0.013941     0.9157       0.9285      \n",
      "7     0.073393     0.013729     0.9177       0.9259      \n",
      "8     0.073187     0.013760     0.9128       0.9289      \n",
      "9     0.072932     0.013880     0.9140       0.9251      \n",
      "10    0.072618     0.013458     0.9157       0.9268      \n",
      "11    0.072358     0.013606     0.9159       0.9259      \n",
      "12    0.072589     0.013645     0.9146       0.9229      \n",
      "13    0.072352     0.013689     0.9158       0.9259      \n",
      "14    0.072265     0.013371     0.9190       0.9234      \n",
      "15    0.072282     0.013234     0.9165       0.9225      \n",
      "16    0.072102     0.013296     0.9151       0.9221      \n",
      "17    0.071995     0.013261     0.9198       0.9247      \n",
      "18    0.071853     0.013258     0.9178       0.9238      \n",
      "19    0.072024     0.013113     0.9181       0.9238      \n",
      "20    0.071859     0.013184     0.9207       0.9229      \n",
      "21    0.071818     0.013138     0.9163       0.9221      \n",
      "22    0.071908     0.013163     0.9137       0.9217      \n",
      "23    0.071625     0.013076     0.9154       0.9217      \n",
      "24    0.071790     0.013002     0.9158       0.9212      \n",
      "25    0.071784     0.012987     0.9146       0.9212      \n",
      "26    0.071454     0.012990     0.9186       0.9212      \n",
      "27    0.071656     0.012986     0.9155       0.9212      \n",
      "28    0.071626     0.012986     0.9155       0.9212      \n",
      "29    0.071558     0.012987     0.9203       0.9212      \n",
      "30    0.071769     0.012984     0.9175       0.9212      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 25439 (\\N{CJK UNIFIED IDEOGRAPH-635F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 35757 (\\N{CJK UNIFIED IDEOGRAPH-8BAD}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 32451 (\\N{CJK UNIFIED IDEOGRAPH-7EC3}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 35777 (\\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:249: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 25439 (\\N{CJK UNIFIED IDEOGRAPH-635F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 35757 (\\N{CJK UNIFIED IDEOGRAPH-8BAD}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 32451 (\\N{CJK UNIFIED IDEOGRAPH-7EC3}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 35777 (\\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_102041/1041620738.py:250: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练曲线保存路径：st_transformer_action_ft_results/visualizations/group_pose_training_curves.png\n",
      "\n",
      "group_pose 微调完成！最优验证损失：0.012984 | 最优验证准确率：0.9212\n",
      "微调模型保存路径：st_transformer_action_ft_results/finetune_models/group_pose_finetuned_best.pth\n"
     ]
    }
   ],
   "source": [
    "# ========== 预训练函数（用第二组数据预训练） ==========\n",
    "def pretrain_with_large_group(pretrain_data):\n",
    "    \"\"\"用第二组（数据量大的组）预训练模型\"\"\"\n",
    "    model = STTransformerAutoencoder().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=PRETRAIN_LR, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=PRETRAIN_EPOCHS)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_acc = 0.0\n",
    "    print(f\"\\n开始用第二组（group_drumming_shaking）预训练（{PRETRAIN_EPOCHS}轮）...\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Epoch':<5} {'Train Loss':<12} {'Val Loss':<12} {'Train Acc':<12} {'Val Acc':<12}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for epoch in range(PRETRAIN_EPOCHS):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch in tqdm(pretrain_data[\"train_loader\"], desc=f\"Pretrain Epoch {epoch+1}\"):\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch = model(batch)\n",
    "            loss = criterion(recon_batch, batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * batch.size(0)\n",
    "            \n",
    "            # 计算准确率\n",
    "            with torch.no_grad():\n",
    "                _, frame_probs = model.get_reconstruction_error(batch)\n",
    "                train_correct += (frame_probs < ANOMALY_THRESHOLD).sum()\n",
    "                train_total += frame_probs.size\n",
    "        \n",
    "        avg_train_loss = train_loss / len(pretrain_data[\"train_loader\"].dataset)\n",
    "        train_acc = train_correct / train_total if train_total > 0 else 0.0\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in pretrain_data[\"test_loader\"]:\n",
    "                batch = batch.to(device)\n",
    "                recon_batch = model(batch)\n",
    "                val_loss += criterion(recon_batch, batch).item() * batch.size(0)\n",
    "                \n",
    "                _, frame_probs = model.get_reconstruction_error(batch)\n",
    "                val_correct += (frame_probs < ANOMALY_THRESHOLD).sum()\n",
    "                val_total += frame_probs.size\n",
    "        \n",
    "        avg_val_loss = val_loss / len(pretrain_data[\"test_loader\"].dataset)\n",
    "        val_acc = val_correct / val_total if val_total > 0 else 0.0\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # 保存最优预训练模型\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            best_acc = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "                'accuracy': best_acc,\n",
    "                'mean': pretrain_data[\"mean\"],\n",
    "                'std': pretrain_data[\"std\"],\n",
    "                'hyperparameters': {\n",
    "                    'd_model': D_MODEL,\n",
    "                    'nhead': NHEAD,\n",
    "                    'num_layers': NUM_LAYERS,\n",
    "                    'dropout': DROPOUT,\n",
    "                    'pretrain_lr': PRETRAIN_LR\n",
    "                }\n",
    "            }, PRETRAIN_MODEL_PATH)\n",
    "        \n",
    "        print(f\"{epoch+1:<5} {avg_train_loss:<12.6f} {avg_val_loss:<12.6f} {train_acc:<12.4f} {val_acc:<12.4f}\")\n",
    "    \n",
    "    print(f\"\\n预训练完成！最优验证损失：{best_loss:.6f} | 最优验证准确率：{best_acc:.4f}\")\n",
    "    print(f\"预训练模型保存路径：{PRETRAIN_MODEL_PATH}\")\n",
    "    return model\n",
    "\n",
    "# ========== 微调函数（用预训练权重微调其他组） ==========\n",
    "def finetune_other_groups(finetune_groups, pretrain_model_path):\n",
    "    \"\"\"用第二组的预训练权重微调另外两个组\"\"\"\n",
    "    finetuned_models = {}\n",
    "    \n",
    "    for group_name, group_data in finetune_groups.items():\n",
    "        print(f\"\\n========== 开始微调 {group_name} ==========\")\n",
    "        \n",
    "        # 加载预训练模型\n",
    "        model = STTransformerAutoencoder().to(device)\n",
    "        pretrain_ckpt = torch.load(pretrain_model_path, map_location=device)\n",
    "        model.load_state_dict(pretrain_ckpt['model_state_dict'])\n",
    "        \n",
    "        # 可选：冻结编码器（根据需求调整）\n",
    "        # for param in model.encoder.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        \n",
    "        # 定义优化器（只优化解码器或全部参数）\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=FINETUNE_LR, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=FINETUNE_EPOCHS)\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        best_acc = 0.0\n",
    "        train_losses, val_losses = [], []\n",
    "        train_accs, val_accs = [], []\n",
    "        \n",
    "        # 微调模型保存路径（按组命名）\n",
    "        finetune_model_path = os.path.join(FINETUNE_DIR, f\"{group_name}_finetuned_best.pth\")\n",
    "        \n",
    "        print(f\"\\n开始微调 {group_name}（{FINETUNE_EPOCHS}轮）...\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"{'Epoch':<5} {'Train Loss':<12} {'Val Loss':<12} {'Train Acc':<12} {'Val Acc':<12}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for epoch in range(FINETUNE_EPOCHS):\n",
    "            # 训练阶段\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for batch in group_data[\"train_loader\"]:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                recon_batch = model(batch)\n",
    "                loss = criterion(recon_batch, batch)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item() * batch.size(0)\n",
    "                \n",
    "                # 计算准确率\n",
    "                with torch.no_grad():\n",
    "                    _, frame_probs = model.get_reconstruction_error(batch)\n",
    "                    train_correct += (frame_probs < ANOMALY_THRESHOLD).sum()\n",
    "                    train_total += frame_probs.size\n",
    "            \n",
    "            avg_train_loss = train_loss / len(group_data[\"train_dataset\"])\n",
    "            train_acc = train_correct / train_total if train_total > 0 else 0.0\n",
    "            train_losses.append(avg_train_loss)\n",
    "            train_accs.append(train_acc)\n",
    "            \n",
    "            # 验证阶段\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in group_data[\"test_loader\"]:\n",
    "                    batch = batch.to(device)\n",
    "                    recon_batch = model(batch)\n",
    "                    val_loss += criterion(recon_batch, batch).item() * batch.size(0)\n",
    "                    \n",
    "                    _, frame_probs = model.get_reconstruction_error(batch)\n",
    "                    val_correct += (frame_probs < ANOMALY_THRESHOLD).sum()\n",
    "                    val_total += frame_probs.size\n",
    "            \n",
    "            avg_val_loss = val_loss / len(group_data[\"test_dataset\"])\n",
    "            val_acc = val_correct / val_total if val_total > 0 else 0.0\n",
    "            val_losses.append(avg_val_loss)\n",
    "            val_accs.append(val_acc)\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            # 保存最优微调模型\n",
    "            if avg_val_loss < best_loss:\n",
    "                best_loss = avg_val_loss\n",
    "                best_acc = val_acc\n",
    "                torch.save({\n",
    "                    'group_name': group_name,\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_loss': best_loss,\n",
    "                    'best_accuracy': best_acc,\n",
    "                    'mean': group_data[\"mean\"],\n",
    "                    'std': group_data[\"std\"],\n",
    "                    'train_losses': train_losses,\n",
    "                    'val_losses': val_losses,\n",
    "                    'train_accs': train_accs,\n",
    "                    'val_accs': val_accs,\n",
    "                    'hyperparameters': {\n",
    "                        'finetune_lr': FINETUNE_LR,\n",
    "                        'batch_size': BATCH_SIZE,\n",
    "                        'epochs': FINETUNE_EPOCHS\n",
    "                    }\n",
    "                }, finetune_model_path)\n",
    "            \n",
    "            print(f\"{epoch+1:<5} {avg_train_loss:<12.6f} {avg_val_loss:<12.6f} {train_acc:<12.4f} {val_acc:<12.4f}\")\n",
    "        \n",
    "        # 绘制训练曲线\n",
    "        plot_training_curves(group_name, train_losses, val_losses, train_accs, val_accs)\n",
    "        \n",
    "        # 保存微调后的模型信息\n",
    "        finetuned_models[group_name] = {\n",
    "            \"model\": model,\n",
    "            \"model_path\": finetune_model_path,\n",
    "            \"best_loss\": best_loss,\n",
    "            \"best_acc\": best_acc,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"val_losses\": val_losses,\n",
    "            \"train_accs\": train_accs,\n",
    "            \"val_accs\": val_accs\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{group_name} 微调完成！最优验证损失：{best_loss:.6f} | 最优验证准确率：{best_acc:.4f}\")\n",
    "        print(f\"微调模型保存路径：{finetune_model_path}\")\n",
    "    \n",
    "    return finetuned_models\n",
    "\n",
    "# ========== 训练曲线绘制函数 ==========\n",
    "def plot_training_curves(group_name, train_losses, val_losses, train_accs, val_accs):\n",
    "    \"\"\"绘制训练曲线（保存到可视化目录）\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # 损失曲线\n",
    "    ax1.plot(train_losses, label='训练损失', color='#1f77b4', linewidth=2, marker='.')\n",
    "    ax1.plot(val_losses, label='验证损失', color='#ff7f0e', linewidth=2, marker='.')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('MSE损失')\n",
    "    ax1.set_title(f'{group_name} 损失曲线')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # 准确率曲线\n",
    "    ax2.plot(train_accs, label='训练准确率', color='#2ca02c', linewidth=2, marker='.')\n",
    "    ax2.plot(val_accs, label='验证准确率', color='#d62728', linewidth=2, marker='.')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('准确率')\n",
    "    ax2.set_title(f'{group_name} 准确率曲线')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 保存图片\n",
    "    plot_path = os.path.join(VISUALIZATION_DIR, f\"{group_name}_training_curves.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"训练曲线保存路径：{plot_path}\")\n",
    "\n",
    "# ========== 执行预训练+微调 ==========\n",
    "# 1. 用第二组预训练\n",
    "pretrain_model = pretrain_with_large_group(pretrain_data)\n",
    "\n",
    "# 2. 微调另外两个组\n",
    "finetuned_models = finetune_other_groups(finetune_groups, PRETRAIN_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1764017308650,
     "user": {
      "displayName": "Aurora Cao",
      "userId": "01537032954294902123"
     },
     "user_tz": -480
    },
    "id": "xlz5m7oFxVfQ",
    "outputId": "119df9c0-6d3a-47d6-eb81-9f16aab246e2"
   },
   "outputs": [],
   "source": [
    "# ========== 异常检测函数 ==========\n",
    "def detect_anomaly(group_name, model, test_dataset, test_loader):\n",
    "    \"\"\"对动作组进行帧级异常检测（结果保存到新路径）\"\"\"\n",
    "    model.eval()\n",
    "    all_seq_probs = []\n",
    "    all_frame_probs = []\n",
    "    all_file_names = []\n",
    "    all_frame_indices = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            batch = batch.to(device)\n",
    "            seq_probs, frame_probs = model.get_reconstruction_error(batch)\n",
    "            \n",
    "            # 获取当前batch的文件名和帧索引\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = min(start_idx + BATCH_SIZE, len(test_dataset))\n",
    "            batch_files = test_dataset.file_names[start_idx:end_idx]\n",
    "            \n",
    "            # 记录结果\n",
    "            all_seq_probs.extend(seq_probs.tolist())\n",
    "            all_frame_probs.extend(frame_probs.tolist())\n",
    "            all_file_names.extend(batch_files)\n",
    "            all_frame_indices.extend([list(range(TARGET_FRAMES)) for _ in range(len(batch_files))])\n",
    "    \n",
    "    # 整理结果为DataFrame\n",
    "    results = []\n",
    "    for i in range(len(all_file_names)):\n",
    "        for frame_idx in range(TARGET_FRAMES):\n",
    "            results.append({\n",
    "                'file_name': all_file_names[i],\n",
    "                'frame_idx': frame_idx,\n",
    "                'frame_anomaly_prob': all_frame_probs[i][frame_idx],\n",
    "                'sequence_anomaly_prob': all_seq_probs[i],\n",
    "                'is_anomaly': 1 if all_frame_probs[i][frame_idx] >= ANOMALY_THRESHOLD else 0\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # 保存检测结果（新路径）\n",
    "    results_path = os.path.join(RESULTS_DIR, f\"{group_name}_anomaly_detection_results.csv\")\n",
    "    results_df.to_csv(results_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    # 统计摘要\n",
    "    total_frames = len(results_df)\n",
    "    anomaly_frames = results_df['is_anomaly'].sum()\n",
    "    anomaly_rate = (anomaly_frames / total_frames) * 100\n",
    "    \n",
    "    print(f\"\\n{group_name} 异常检测结果：\")\n",
    "    print(f\"- 总帧数：{total_frames}\")\n",
    "    print(f\"- 异常帧数：{anomaly_frames}（{anomaly_rate:.2f}%）\")\n",
    "    print(f\"- 结果保存路径：{results_path}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# ========== 详细可视化函数（更新可视化路径） ==========\n",
    "def plot_training_curves(group_name, train_losses, val_losses, train_accs, val_accs):\n",
    "    \"\"\"绘制训练曲线（保存到可视化目录）\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # 损失曲线\n",
    "    ax1.plot(train_losses, label='训练损失', color='#1f77b4', linewidth=2, marker='.')\n",
    "    ax1.plot(val_losses, label='验证损失', color='#ff7f0e', linewidth=2, marker='.')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('MSE损失')\n",
    "    ax1.set_title(f'{group_name} 损失曲线')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # 准确率曲线\n",
    "    ax2.plot(train_accs, label='训练准确率', color='#2ca02c', linewidth=2, marker='.')\n",
    "    ax2.plot(val_accs, label='验证准确率', color='#d62728', linewidth=2, marker='.')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('准确率')\n",
    "    ax2.set_title(f'{group_name} 准确率曲线')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 保存图片（新路径）\n",
    "    plot_path = os.path.join(VISUALIZATION_DIR, f\"{group_name}_training_curves.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"训练曲线保存路径：{plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197313,
     "status": "ok",
     "timestamp": 1764017600475,
     "user": {
      "displayName": "Aurora Cao",
      "userId": "01537032954294902123"
     },
     "user_tz": -480
    },
    "id": "-PRd-zIuX0ua",
    "outputId": "93fc8254-b5a7-429e-e640-21254768f9b2"
   },
   "outputs": [],
   "source": [
    "def detect_anomaly(group_name, model, test_dataset, test_loader):\n",
    "    \"\"\"对动作组进行帧级异常检测\"\"\"\n",
    "    model.eval()\n",
    "    all_seq_probs = []\n",
    "    all_frame_probs = []\n",
    "    all_file_names = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            batch = batch.to(device)\n",
    "            seq_probs, frame_probs = model.get_reconstruction_error(batch)\n",
    "            \n",
    "            all_seq_probs.extend(seq_probs)\n",
    "            all_frame_probs.extend(frame_probs)\n",
    "            \n",
    "            # 获取文件名\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = min(start_idx + BATCH_SIZE, len(test_dataset))\n",
    "            all_file_names.extend(test_dataset.file_names[start_idx:end_idx])\n",
    "    \n",
    "    # 生成检测结果DataFrame\n",
    "    frame_results = []\n",
    "    for seq_idx, (file_name, seq_prob, frame_probs) in enumerate(zip(all_file_names, all_seq_probs, all_frame_probs)):\n",
    "        for frame_idx in range(TARGET_FRAMES):\n",
    "            frame_results.append({\n",
    "                'group_name': group_name,\n",
    "                'file_name': file_name,\n",
    "                'sequence_idx': seq_idx,\n",
    "                'frame_idx': frame_idx,\n",
    "                'sequence_anomaly_prob': round(seq_prob, 4),\n",
    "                'frame_anomaly_prob': round(frame_probs[frame_idx], 4),\n",
    "                'is_anomaly': frame_probs[frame_idx] >= ANOMALY_THRESHOLD\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(frame_results)\n",
    "    \n",
    "    # 保存结果\n",
    "    results_path = os.path.join(OUTPUT_DIR, f'{group_name}_anomaly_results.csv')\n",
    "    results_df.to_csv(results_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 统计摘要\n",
    "    total_frames = len(results_df)\n",
    "    anomaly_frames = results_df['is_anomaly'].sum()\n",
    "    anomaly_seqs = results_df.groupby('sequence_idx')['is_anomaly'].any().sum()\n",
    "    \n",
    "    print(f\"\\n{group_name} 异常检测结果：\")\n",
    "    print(f\"总帧数：{total_frames} | 异常帧数：{anomaly_frames} ({anomaly_frames/total_frames*100:.2f}%)\")\n",
    "    print(f\"总序列数：{len(all_seq_probs)} | 异常序列数：{anomaly_seqs} ({anomaly_seqs/len(all_seq_probs)*100:.2f}%)\")\n",
    "    print(f\"结果保存路径：{results_path}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# ========== 执行异常检测 ==========\n",
    "all_detection_results = {}\n",
    "for group_name, info in trained_models.items():\n",
    "    results_df = detect_anomaly(\n",
    "        group_name=group_name,\n",
    "        model=info['model'],\n",
    "        test_dataset=info['test_dataset'],\n",
    "        test_loader=info['test_loader']\n",
    "    )\n",
    "    all_detection_results[group_name] = results_df\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"所有动作组训练和检测完成！\")\n",
    "print(f\"结果保存在：{OUTPUT_DIR}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_2d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 289\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_logs_with_frames.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    287\u001b[0m     log_data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m--> 289\u001b[0m detailed_visualization_with_frames(log_data, label_names\u001b[38;5;241m=\u001b[39m\u001b[43mdataset_2d\u001b[49m\u001b[38;5;241m.\u001b[39mlabel_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_2d' is not defined"
     ]
    }
   ],
   "source": [
    "# %% 单元格7：详细可视化分析（多帧数+多模态对比，修复类别数不匹配问题）\n",
    "def detailed_visualization_with_frames(log_data, label_names):\n",
    "    \"\"\"\n",
    "    详细可视化分析（支持多帧数分组）：\n",
    "    1. 各分组损失/准确率曲线对比\n",
    "    2. 多模态+多帧数指标雷达图\n",
    "    3. 混淆矩阵（按分组展示）\n",
    "    4. 类别级准确率对比\n",
    "    5. 分类报告热力图\n",
    "    \"\"\"\n",
    "    # 修复字体问题：使用通用英文字体，避免中文依赖\n",
    "    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Helvetica', 'sans-serif']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.rcParams['figure.figsize'] = (18, 12)  # 扩大图表尺寸，适配英文标签\n",
    "    plt.rcParams['font.size'] = 11\n",
    "\n",
    "    results_2d = log_data['2d']\n",
    "    results_3d = log_data['3d']\n",
    "    supported_frames = log_data['params']['supported_frames']\n",
    "    epochs = log_data['params']['epochs']\n",
    "    epochs_range = range(1, epochs + 1)\n",
    "\n",
    "    # 颜色方案（兼容大小写）\n",
    "    colors_modality = {'2d': '#2E86AB', '3d': '#A23B72', '2D': '#2E86AB', '3D': '#A23B72'}\n",
    "    colors_frame = {32: '#F18F01', 64: '#C73E1D'}\n",
    "\n",
    "    # ========== 图1：损失曲线对比（所有分组） ==========\n",
    "    plt.subplot(2, 3, 1)\n",
    "    for modality, results in [('2d', results_2d), ('3d', results_3d)]:\n",
    "        for frame_num, res in results.items():\n",
    "            train_loss = res['train_log']['loss']\n",
    "            test_loss = res['test_log']['loss']\n",
    "            label = f'{modality.upper()}-{frame_num}f'\n",
    "            plt.plot(epochs_range, train_loss, label=f'{label}-Train', \n",
    "                     color=colors_modality[modality], linewidth=2, \n",
    "                     linestyle='-' if frame_num == 32 else '--')\n",
    "            plt.plot(epochs_range, test_loss, label=f'{label}-Test', \n",
    "                     color=colors_modality[modality], linewidth=2, \n",
    "                     linestyle=':' if frame_num == 32 else '-.')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Curve Comparison (All Groups)')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ========== 图2：准确率曲线对比（所有分组） ==========\n",
    "    plt.subplot(2, 3, 2)\n",
    "    for modality, results in [('2d', results_2d), ('3d', results_3d)]:\n",
    "        for frame_num, res in results.items():\n",
    "            train_acc = res['train_log']['acc']\n",
    "            test_acc = res['test_log']['acc']\n",
    "            best_acc = res['best_metrics']['acc']\n",
    "            best_epoch = res['best_metrics']['epoch']\n",
    "            label = f'{modality.upper()}-{frame_num}f'\n",
    "            # 绘制曲线\n",
    "            plt.plot(epochs_range, train_acc, label=f'{label}-Train', \n",
    "                     color=colors_modality[modality], linewidth=2, \n",
    "                     linestyle='-' if frame_num == 32 else '--')\n",
    "            plt.plot(epochs_range, test_acc, label=f'{label}-Test', \n",
    "                     color=colors_modality[modality], linewidth=2, \n",
    "                     linestyle=':' if frame_num == 32 else '-.')\n",
    "            # 标注最佳准确率\n",
    "            plt.scatter(best_epoch, best_acc, color=colors_modality[modality], s=50, zorder=5)\n",
    "            plt.annotate(f'{best_acc:.3f}', \n",
    "                         xy=(best_epoch, best_acc), \n",
    "                         xytext=(best_epoch+1, best_acc-0.05),\n",
    "                         color=colors_modality[modality], fontsize=8)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Curve Comparison (All Groups)')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ========== 图3：多指标雷达图（最佳分组对比） ==========\n",
    "    plt.subplot(2, 3, 3)\n",
    "    # 收集所有分组的最佳指标\n",
    "    radar_data = []\n",
    "    labels_radar = []\n",
    "    for modality, results in [('2d', results_2d), ('3d', results_3d)]:\n",
    "        for frame_num, res in results.items():\n",
    "            metrics = [\n",
    "                res['best_metrics']['acc'],\n",
    "                res['best_metrics']['precision'],\n",
    "                res['best_metrics']['recall'],\n",
    "                res['best_metrics']['f1']\n",
    "            ]\n",
    "            radar_data.append(metrics)\n",
    "            labels_radar.append(f'{modality.upper()}-{frame_num}f')\n",
    "    \n",
    "    # 雷达图设置（英文指标名）\n",
    "    metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    angles = np.linspace(0, 2*np.pi, len(metrics_names), endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "    metrics_names += metrics_names[:1]\n",
    "\n",
    "    # 绘制雷达图（修复标签格式）\n",
    "    for i, (data, label) in enumerate(zip(radar_data, labels_radar)):\n",
    "        data += data[:1]\n",
    "        # 兼容标签格式（提取模态部分，转为小写）\n",
    "        modality_part = label.split('-')[0].lower()\n",
    "        color = colors_modality[modality_part]\n",
    "        plt.polar(angles, data, label=label, color=color, linewidth=2, marker='o', markersize=3)\n",
    "        plt.fill(angles, data, color=color, alpha=0.1)\n",
    "    \n",
    "    plt.xticks(angles[:-1], metrics_names[:-1], fontsize=10)\n",
    "    plt.yticks([0.2, 0.4, 0.6, 0.8, 1.0], ['0.2', '0.4', '0.6', '0.8', '1.0'], alpha=0.7)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.title('Multi-Metric Radar Chart (All Groups)', pad=20)\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0), fontsize=9)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ========== 图4：混淆矩阵（最佳性能分组） ==========\n",
    "    plt.subplot(2, 3, 4)\n",
    "    # 找到最佳F1的分组\n",
    "    best_f1 = 0.0\n",
    "    best_conf = None\n",
    "    best_label = \"\"\n",
    "    best_res = None\n",
    "    for modality, results in [('2d', results_2d), ('3d', results_3d)]:\n",
    "        for frame_num, res in results.items():\n",
    "            if res['best_metrics']['f1'] > best_f1:\n",
    "                best_f1 = res['best_metrics']['f1']\n",
    "                best_preds = res['best_metrics']['preds']\n",
    "                best_true = res['best_metrics']['labels']\n",
    "                # 获取该分组实际存在的类别ID（去重并排序）\n",
    "                actual_class_ids = sorted(list(set(best_true) | set(best_preds)))\n",
    "                best_conf = confusion_matrix(best_true, best_preds, labels=actual_class_ids)\n",
    "                best_label = f'{modality.upper()}-{frame_num}f'\n",
    "                best_res = res  # 保存最佳结果\n",
    "    \n",
    "    # 关键修复：按实际类别ID过滤target_names，确保一一对应\n",
    "    actual_class_names = [label_names[class_id] for class_id in actual_class_ids]\n",
    "    \n",
    "    # 绘制最佳分组混淆矩阵\n",
    "    cm_norm = best_conf.astype('float') / best_conf.sum(axis=1)[:, np.newaxis] * 100\n",
    "    sns.heatmap(cm_norm, annot=best_conf, fmt='d', cmap='Blues',\n",
    "                xticklabels=actual_class_names, yticklabels=actual_class_names,\n",
    "                cbar_kws={'label': 'Accuracy (%)'},\n",
    "                annot_kws={'fontsize': 9})\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix (Best Group: {best_label}, F1: {best_f1:.3f})')\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=9)\n",
    "    plt.yticks(rotation=0, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ========== 图5：类别级准确率对比（所有分组） ==========\n",
    "    plt.subplot(2, 3, 5)\n",
    "    x = np.arange(len(actual_class_names))  # 使用实际类别数\n",
    "    width = 0.15  # 柱宽\n",
    "    offset = -len(radar_data)*width/2  # 偏移量\n",
    "\n",
    "    for i, (label, _) in enumerate(zip(labels_radar, radar_data)):\n",
    "        # 解析分组信息（修复格式）\n",
    "        modality_part = label.split('-')[0].lower()\n",
    "        frame_num = int(label.split('-')[1][:-1])\n",
    "        res = results_2d[frame_num] if modality_part == '2d' else results_3d[frame_num]\n",
    "        group_preds = res['best_metrics']['preds']\n",
    "        group_true = res['best_metrics']['labels']\n",
    "        \n",
    "        # 计算该分组的类别级准确率（仅包含实际存在的类别）\n",
    "        class_acc = []\n",
    "        for class_id in actual_class_ids:\n",
    "            mask = group_true == class_id\n",
    "            if mask.sum() > 0:\n",
    "                acc = (group_preds[mask] == class_id).sum() / mask.sum()\n",
    "            else:\n",
    "                acc = 0.0\n",
    "            class_acc.append(acc)\n",
    "        \n",
    "        # 绘制柱状图\n",
    "        plt.bar(x + offset + i*width, class_acc, width, label=label, \n",
    "                color=colors_modality[modality_part], alpha=0.8)\n",
    "        # 标注数值（只标注前3个分组，避免拥挤）\n",
    "        if i < 3:\n",
    "            for k, v in enumerate(class_acc):\n",
    "                plt.text(x[k] + offset + i*width, v + 0.02, f'{v:.2f}', \n",
    "                         ha='center', va='bottom', fontsize=7)\n",
    "    \n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Class Accuracy')\n",
    "    plt.title('Class-Level Accuracy Comparison (All Groups)')\n",
    "    plt.xticks(x, actual_class_names, rotation=45, ha='right', fontsize=9)\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    plt.grid(alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ========== 图6：各分组核心指标汇总 ==========\n",
    "    plt.subplot(2, 3, 6)\n",
    "    # 收集核心指标\n",
    "    frame_nums = []\n",
    "    accs_2d = []\n",
    "    accs_3d = []\n",
    "    for frame_num in supported_frames:\n",
    "        frame_nums.append(f'{frame_num}f')  # 简化标签为\"32f\"/\"64f\"\n",
    "        accs_2d.append(results_2d[frame_num]['best_metrics']['acc'] if frame_num in results_2d else 0)\n",
    "        accs_3d.append(results_3d[frame_num]['best_metrics']['acc'] if frame_num in results_3d else 0)\n",
    "    \n",
    "    # 绘制分组对比柱状图\n",
    "    x = np.arange(len(frame_nums))\n",
    "    width = 0.35\n",
    "    plt.bar(x - width/2, accs_2d, width, label='2D Modality', color=colors_modality['2d'], alpha=0.8)\n",
    "    plt.bar(x + width/2, accs_3d, width, label='3D Modality', color=colors_modality['3d'], alpha=0.8)\n",
    "    # 标注数值\n",
    "    for i, v in enumerate(accs_2d):\n",
    "        if v > 0:\n",
    "            plt.text(i - width/2, v + 0.02, f'{v:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    for i, v in enumerate(accs_3d):\n",
    "        if v > 0:\n",
    "            plt.text(i + width/2, v + 0.02, f'{v:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    plt.xlabel('Frame Number')\n",
    "    plt.ylabel('Best Accuracy')\n",
    "    plt.title('Accuracy Comparison (Modality x Frames)')\n",
    "    plt.xticks(x, frame_nums, fontsize=10)\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存综合图表\n",
    "    plt.savefig('comprehensive_visualization_with_frames.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # ========== 额外：分类报告热力图（最佳分组） ==========\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # 最佳分组分类报告（使用实际类别ID和类别名）\n",
    "    best_preds = best_res['best_metrics']['preds']\n",
    "    best_true = best_res['best_metrics']['labels']\n",
    "    \n",
    "    # 生成分类报告（指定labels参数，确保与target_names匹配）\n",
    "    report = classification_report(\n",
    "        best_true, best_preds, \n",
    "        labels=actual_class_ids,  # 关键：指定实际存在的类别ID\n",
    "        target_names=actual_class_names,  # 过滤后的类别名\n",
    "        output_dict=True,\n",
    "        zero_division=0  # 避免除以零警告\n",
    "    )\n",
    "    report_df = pd.DataFrame(report).T[:-3]  # 去除avg和total行\n",
    "    report_df = report_df[['precision', 'recall', 'f1-score']]\n",
    "\n",
    "    # 绘制热力图\n",
    "    sns.heatmap(report_df, annot=True, cmap='Blues', vmin=0, vmax=1, fmt='.3f',\n",
    "                annot_kws={'fontsize': 10},\n",
    "                cbar_kws={'label': 'Score'})\n",
    "    plt.title(f'Classification Report (Best Group: {best_label}, F1: {best_f1:.3f})', fontsize=12)\n",
    "    plt.xlabel('Metrics', fontsize=11)\n",
    "    plt.ylabel('Classes', fontsize=11)\n",
    "    plt.xticks(rotation=0, fontsize=10)\n",
    "    plt.yticks(rotation=0, fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('best_group_classification_report.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # ========== 输出详细文字报告 ==========\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📋 Detailed Performance Comparison Report (Modality x Frames)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Group':<12} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Sample Size':<10}\")\n",
    "    print(\"-\"*80)\n",
    "    for modality, results in [('2d', results_2d), ('3d', results_3d)]:\n",
    "        for frame_num, res in results.items():\n",
    "            group_name = f'{modality.upper()}-{frame_num}f'\n",
    "            acc = res['best_metrics']['acc']\n",
    "            prec = res['best_metrics']['precision']\n",
    "            rec = res['best_metrics']['recall']\n",
    "            f1 = res['best_metrics']['f1']\n",
    "            sample_num = res['train_samples'] + res['test_samples']\n",
    "            print(f\"{group_name:<12} {acc:.4f}     {prec:.4f}     {rec:.4f}     {f1:.4f}     {sample_num:<10}\")\n",
    "\n",
    "    print(f\"\\n🏆 Best Group: {best_label}\")\n",
    "    print(f\"  Best F1-Score: {best_f1:.4f}\")\n",
    "    print(f\"  Best Accuracy: {best_res['best_metrics']['acc']:.4f}\")\n",
    "    print(f\"  Actual Classes: {actual_class_names}\")  # 显示实际训练的类别\n",
    "    print(f\"  Corresponding Model Path: {best_res['model_path']}\")\n",
    "\n",
    "    print(f\"\\n📁 Generated Visualization Files:\")\n",
    "    print(f\"  1. comprehensive_visualization_with_frames.png (Comprehensive Comparison)\")\n",
    "    print(f\"  2. best_group_classification_report.png (Best Group Classification Report)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# 加载训练日志并执行可视化\n",
    "with open('training_logs_with_frames.pkl', 'rb') as f:\n",
    "    log_data = pickle.load(f)\n",
    "\n",
    "detailed_visualization_with_frames(log_data, label_names=dataset_2d.label_names)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOO5LM6QoKLbY8D7mtsxFJJ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mmasd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
