{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14463,
     "status": "ok",
     "timestamp": 1764045990680,
     "user": {
      "displayName": "Aurora Cao",
      "userId": "01537032954294902123"
     },
     "user_tz": -480
    },
    "id": "c-Kp3XYt2GrF",
    "outputId": "8e9f06d2-1279-4adb-d070-57c027d860df"
   },
   "outputs": [],
   "source": [
    "# 安装依赖（仅需执行一次）\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_dependencies():\n",
    "    dependencies = [\n",
    "        \"torch\", \"torchvision\", \"numpy\", \"pandas\", \"matplotlib\",\n",
    "        \"scikit-learn\", \"tqdm\", \"pickle-mixin\"\n",
    "    ]\n",
    "    for dep in dependencies:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", dep])\n",
    "\n",
    "# 执行安装（首次运行时取消注释）\n",
    "# install_dependencies()\n",
    "print(\"依赖安装完成（若未安装，取消上方注释执行）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2477,
     "status": "ok",
     "timestamp": 1764044494400,
     "user": {
      "displayName": "Aurora Cao",
      "userId": "01537032954294902123"
     },
     "user_tz": -480
    },
    "id": "eOHH5Al4L8I3",
    "outputId": "4fda6f96-a3ac-4e61-f64e-a6950a78aa51"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cfg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 导入分区1的配置\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcfg\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# ========== 数据读取工具 ==========\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_all_pkl_files\u001b[39m():\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cfg'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 中文显示配置\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 支持中文\n",
    "plt.rcParams['axes.unicode_minus'] = False    # 解决负号显示问题\n",
    "plt.rcParams['figure.figsize'] = (15, 10)     # 默认图表大小\n",
    "plt.rcParams['font.size'] = 10                # 默认字体大小\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备：{device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU型号：{torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU内存：{torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "# ========== 关键配置 ==========\n",
    "PKL_2D_DIR = '/root/second/2D'  # 你的2D pkl文件夹\n",
    "PKL_3D_DIR = '/root/second/3D'  # 你的3D pkl文件夹\n",
    "MODALITY = '3d'  # 选择检测模态：'2d' 或 '3d'（3D更精准）\n",
    "MAX_FRAMES = 32  # 统一帧长（不足补0，超出截断）\n",
    "SUPPORTED_FRAMES = [32, 64]  # 支持的原始帧数\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 30\n",
    "ANOMALY_THRESHOLD = 0.8  # 异常帧阈值（0-1，越大越严格，基于概率）\n",
    "NUM_JOINTS = 71  # 骨架关节数（根据你的数据调整，原代码默认71）\n",
    "\n",
    "# 输出目录（保存异常帧结果和可视化）\n",
    "OUTPUT_DIR = 'asd_anomaly_detection_results_frame_level'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "B2pL8zYohef_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前选择模态：3d\n",
      "找到的PKL文件数：11\n",
      "所有可用Theme：['arm_swing_as', 'body_swing_bs', 'chest_expansion_ce', 'drumming_dr', 'frog_pose_fg', 'maracas_forward_shaking_mfs', 'maracas_shaking_ms', 'sing_and_clap_sac', 'squat_sq', 'tree_pose_tr', 'twist_pose_tw']\n"
     ]
    }
   ],
   "source": [
    "# 补充缺失的get_pkl_files函数\n",
    "def get_pkl_files(dir_path):\n",
    "    \"\"\"获取目录下所有pkl文件\"\"\"\n",
    "    return [os.path.join(dir_path, f) for f in os.listdir(dir_path) if f.endswith('.pkl')]\n",
    "\n",
    "# 获取所有Theme名称（从PKL文件中提取）\n",
    "def get_all_themes(pkl_files):\n",
    "    themes = set()\n",
    "    for file_path in pkl_files:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        themes.add(data['metadata']['theme_name'])\n",
    "    return sorted(list(themes))\n",
    "\n",
    "# 加载指定模态的PKL文件并获取所有Theme\n",
    "pkl_files = get_pkl_files(PKL_2D_DIR) if MODALITY == '2d' else get_pkl_files(PKL_3D_DIR)\n",
    "all_themes = get_all_themes(pkl_files)\n",
    "\n",
    "print(f\"当前选择模态：{MODALITY}\")\n",
    "print(f\"找到的PKL文件数：{len(pkl_files)}\")\n",
    "print(f\"所有可用Theme：{all_themes}\")\n",
    "\n",
    "# 验证文件存在\n",
    "assert len(pkl_files) > 0, f\"未找到{MODALITY}模态的PKL文件，请检查路径\"\n",
    "assert len(all_themes) > 0, \"未从PKL文件中提取到Theme信息\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1437621,
     "status": "ok",
     "timestamp": 1764045939406,
     "user": {
      "displayName": "Aurora Cao",
      "userId": "01537032954294902123"
     },
     "user_tz": -480
    },
    "id": "E2k76vUXTG70",
    "outputId": "136f9146-d9bf-4941-9708-ad4650c4903c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载目标Theme：arm_swing_as，样本数：105\n",
      "\n",
      "目标Theme：arm_swing_as\n",
      "总Sample数：105\n",
      "总帧数：3360\n",
      "帧数据形状：(3360, 71, 3)（帧数×关节数×通道数）\n",
      "每个Sample的平均帧数：32.0\n",
      "加载目标Theme：body_swing_bs，样本数：119\n",
      "\n",
      "目标Theme：body_swing_bs\n",
      "总Sample数：119\n",
      "总帧数：3808\n",
      "帧数据形状：(3808, 71, 3)（帧数×关节数×通道数）\n",
      "每个Sample的平均帧数：32.0\n",
      "加载目标Theme：chest_expansion_ce，样本数：114\n",
      "\n",
      "目标Theme：chest_expansion_ce\n",
      "总Sample数：114\n",
      "总帧数：7296\n",
      "帧数据形状：(7296, 71, 3)（帧数×关节数×通道数）\n",
      "每个Sample的平均帧数：64.0\n",
      "加载目标Theme：drumming_dr，样本数：545\n",
      "\n",
      "目标Theme：drumming_dr\n",
      "总Sample数：545\n",
      "总帧数：17440\n",
      "帧数据形状：(17440, 71, 3)（帧数×关节数×通道数）\n",
      "每个Sample的平均帧数：32.0\n",
      "加载目标Theme：frog_pose_fg，样本数：113\n",
      "\n",
      "目标Theme：frog_pose_fg\n",
      "总Sample数：113\n",
      "总帧数：3616\n",
      "帧数据形状：(3616, 71, 3)（帧数×关节数×通道数）\n",
      "每个Sample的平均帧数：32.0\n",
      "加载目标Theme：maracas_forward_shaking_mfs，样本数：103\n",
      "\n",
      "目标Theme：maracas_forward_shaking_mfs\n",
      "总Sample数：103\n",
      "总帧数：6592\n",
      "帧数据形状：(6592, 71, 3)（帧数×关节数×通道数）\n",
      "每个Sample的平均帧数：64.0\n",
      "加载目标Theme：maracas_shaking_ms，样本数：130\n",
      "\n",
      "目标Theme：maracas_shaking_ms\n",
      "总Sample数：130\n",
      "总帧数：8320\n",
      "帧数据形状：(8320, 71, 3)（帧数×关节数×通道数）\n",
      "每个Sample的平均帧数：64.0\n",
      "加载目标Theme：sing_and_clap_sac，样本数：113\n",
      "\n",
      "目标Theme：sing_and_clap_sac\n",
      "总Sample数：113\n",
      "总帧数：7232\n",
      "帧数据形状：(7232, 71, 3)（帧数×关节数×通道数）\n",
      "每个Sample的平均帧数：64.0\n",
      "加载目标Theme：squat_sq，样本数：102\n",
      "\n",
      "目标Theme：squat_sq\n",
      "总Sample数：102\n",
      "总帧数：6528\n",
      "帧数据形状：(6528, 71, 3)（帧数×关节数×通道数）\n",
      "每个Sample的平均帧数：64.0\n",
      "加载目标Theme：tree_pose_tr，样本数：129\n",
      "\n",
      "目标Theme：tree_pose_tr\n",
      "总Sample数：129\n",
      "总帧数：8256\n",
      "帧数据形状：(8256, 71, 3)（帧数×关节数×通道数）\n",
      "每个Sample的平均帧数：64.0\n",
      "加载目标Theme：twist_pose_tw，样本数：120\n",
      "\n",
      "目标Theme：twist_pose_tw\n",
      "总Sample数：120\n",
      "总帧数：7680\n",
      "帧数据形状：(7680, 71, 3)（帧数×关节数×通道数）\n",
      "每个Sample的平均帧数：64.0\n",
      "\n",
      "有效Theme（有数据）：['arm_swing_as', 'body_swing_bs', 'chest_expansion_ce', 'drumming_dr', 'frog_pose_fg', 'maracas_forward_shaking_mfs', 'maracas_shaking_ms', 'sing_and_clap_sac', 'squat_sq', 'tree_pose_tr', 'twist_pose_tw']\n"
     ]
    }
   ],
   "source": [
    "class AnomalySkeletonDataset(Dataset):\n",
    "    \"\"\"按Theme分组的骨架数据集（帧级别拆分，保留每个帧的sample归属信息）\"\"\"\n",
    "    def __init__(self, pkl_files, modality='3d', target_theme=None, max_frames=32):\n",
    "        self.modality = modality\n",
    "        self.skeleton_key = 'skeleton_2d' if modality == '2d' else 'skeleton_3d'\n",
    "        self.max_frames = max_frames\n",
    "        self.target_theme = target_theme  # 目标Theme（单独为该Theme训练正常模型）\n",
    "        self.frame_data = []  # 帧级别数据：每个元素是单帧骨架\n",
    "        self.frame_info = []  # 帧的元信息（核心：保留sample级归属）\n",
    "        \n",
    "        # 加载目标Theme的所有样本（仅用该Theme的样本训练“正常模型”）\n",
    "        sample_idx = 0  # 全局sample索引（标记每个sample的唯一ID）\n",
    "        for file_path in pkl_files:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            \n",
    "            theme_name = data['metadata']['theme_name']\n",
    "            if theme_name != target_theme:\n",
    "                continue  # 只加载目标Theme的数据\n",
    "            \n",
    "            print(f\"加载目标Theme：{theme_name}，样本数：{data['metadata']['sample_count']}\")\n",
    "            for sample in data['samples']:\n",
    "                skeleton = sample[self.skeleton_key]  # (T, J, C)：帧数×关节数×通道数\n",
    "                motion_name = sample['motion_name']\n",
    "                T = skeleton.shape[0]\n",
    "                \n",
    "                # 帧级别拆分：将每个sample的每帧单独作为一个数据点，保留完整归属信息\n",
    "                for frame_idx in range(T):\n",
    "                    frame = skeleton[frame_idx]  # (J, C)：单帧骨架\n",
    "                    \n",
    "                    # 记录元信息（关键：标注sample_idx、motion_name、frame_idx，便于定位）\n",
    "                    self.frame_info.append({\n",
    "                        'sample_idx': sample_idx,  # 每个sample的唯一ID\n",
    "                        'motion_name': motion_name,  # sample的名称\n",
    "                        'frame_idx': frame_idx,  # 该帧在sample中的索引（0开始）\n",
    "                        'theme': theme_name,\n",
    "                        'is_anomaly': False,  # 初始标记为正常\n",
    "                        'reconstruction_error': 0.0,  # 后续填充重建误差\n",
    "                        'anomaly_score': 0.0,  # 后续填充异常分数（0-1）\n",
    "                        'anomaly_prob': 0.0  # 后续填充异常概率（0-1，越接近1越可能异常）\n",
    "                    })\n",
    "                    self.frame_data.append(frame)\n",
    "                \n",
    "                sample_idx += 1  # 每个sample对应一个唯一索引\n",
    "        \n",
    "        # 数据归一化（按关节和通道归一化，提升模型稳定性）\n",
    "        self.frame_data = np.array(self.frame_data, dtype=np.float32)  # (N, J, C)\n",
    "        self.mean = np.mean(self.frame_data, axis=0, keepdims=True)\n",
    "        self.std = np.std(self.frame_data, axis=0, keepdims=True) + 1e-6  # 避免除零\n",
    "        self.frame_data = (self.frame_data - self.mean) / self.std\n",
    "        \n",
    "        # 统计sample信息\n",
    "        self.sample_count = sample_idx  # 总sample数\n",
    "        self.frame_info_df = pd.DataFrame(self.frame_info)\n",
    "        \n",
    "        print(f\"\\n目标Theme：{target_theme}\")\n",
    "        print(f\"总Sample数：{self.sample_count}\")\n",
    "        print(f\"总帧数：{len(self.frame_data)}\")\n",
    "        print(f\"帧数据形状：{self.frame_data.shape}（帧数×关节数×通道数）\")\n",
    "        print(f\"每个Sample的平均帧数：{len(self.frame_data)/self.sample_count:.1f}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.frame_data[idx], dtype=torch.float32)\n",
    "\n",
    "# 为每个Theme创建单独的数据集（后续逐一训练）\n",
    "theme_datasets = {}\n",
    "for theme in all_themes:\n",
    "    dataset = AnomalySkeletonDataset(\n",
    "        pkl_files=pkl_files,\n",
    "        modality=MODALITY,\n",
    "        target_theme=theme,\n",
    "        max_frames=MAX_FRAMES\n",
    "    )\n",
    "    if len(dataset) > 0:  # 只保留有数据的Theme\n",
    "        theme_datasets[theme] = dataset\n",
    "\n",
    "print(f\"\\n有效Theme（有数据）：{list(theme_datasets.keys())}\")\n",
    "assert len(theme_datasets) > 0, \"无有效Theme数据，无法继续训练\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1764017308650,
     "user": {
      "displayName": "Aurora Cao",
      "userId": "01537032954294902123"
     },
     "user_tz": -480
    },
    "id": "xlz5m7oFxVfQ",
    "outputId": "119df9c0-6d3a-47d6-eb81-9f16aab246e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自编码器模型结构：\n",
      "输入通道数：3（3d模态）\n",
      "关节数：71\n",
      "模型参数总数：0.19M\n"
     ]
    }
   ],
   "source": [
    "class FrameAutoencoder(nn.Module):\n",
    "    \"\"\"帧级别骨架自编码器：学习正常帧的特征，通过重建误差检测异常\"\"\"\n",
    "    def __init__(self, input_channels=3, num_joints=71, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.input_dim = num_joints * input_channels  # 扁平化输入（J×C）\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # 编码器：压缩特征（帧骨架 → 低维特征）\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),  # (B, J, C) → (B, J×C)\n",
    "            nn.Linear(self.input_dim, hidden_dim * 2),\n",
    "            nn.LayerNorm(hidden_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2)  # 瓶颈层\n",
    "        )\n",
    "        \n",
    "        # 解码器：重建帧（低维特征 → 原始帧骨架）\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.LayerNorm(hidden_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim * 2, self.input_dim),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(num_joints, input_channels))  # (B, J×C) → (B, J, C)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 编码 → 解码 → 输出重建结果\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon\n",
    "    \n",
    "    def get_reconstruction_error(self, x):\n",
    "        \"\"\"计算重建误差（MSE）：异常帧的误差会显著高于正常帧\"\"\"\n",
    "        with torch.no_grad():\n",
    "            x_recon = self.forward(x)\n",
    "            mse = torch.mean((x - x_recon) ** 2, dim=[1, 2])  # 按关节和通道求平均\n",
    "        return mse.cpu().numpy()\n",
    "\n",
    "# 初始化模型（根据模态选择输入通道数）\n",
    "input_channels = 2 if MODALITY == '2d' else 3\n",
    "base_model = FrameAutoencoder(\n",
    "    input_channels=input_channels,\n",
    "    num_joints=NUM_JOINTS,\n",
    "    hidden_dim=128\n",
    ").to(device)\n",
    "\n",
    "print(f\"自编码器模型结构：\")\n",
    "print(f\"输入通道数：{input_channels}（{MODALITY}模态）\")\n",
    "print(f\"关节数：{NUM_JOINTS}\")\n",
    "print(f\"模型参数总数：{sum(p.numel() for p in base_model.parameters()) / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197313,
     "status": "ok",
     "timestamp": 1764017600475,
     "user": {
      "displayName": "Aurora Cao",
      "userId": "01537032954294902123"
     },
     "user_tz": -480
    },
    "id": "-PRd-zIuX0ua",
    "outputId": "93fc8254-b5a7-429e-e640-21254768f9b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "处理Theme：arm_swing_as（含训练/测试集8:2划分）\n",
      "====================================================================================================\n",
      "训练集：Sample数=84 | 帧数=2688\n",
      "测试集：Sample数=21 | 帧数=672\n",
      "划分比例：训练集80% | 测试集20%\n",
      "\n",
      "开始训练自编码器（共30个Epoch）\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30] | 平均重建损失：0.059854 | LR：0.000093\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 102\u001b[0m\n\u001b[1;32m     95\u001b[0m model \u001b[38;5;241m=\u001b[39m FrameAutoencoder(\n\u001b[1;32m     96\u001b[0m     input_channels\u001b[38;5;241m=\u001b[39minput_channels,\n\u001b[1;32m     97\u001b[0m     num_joints\u001b[38;5;241m=\u001b[39mNUM_JOINTS,\n\u001b[1;32m     98\u001b[0m     hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m\n\u001b[1;32m     99\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# 训练（仅用训练集）\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m trained_model, train_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_autoencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\n\u001b[1;32m    107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# -------------------------- 保存模型（新增测试集相关信息） --------------------------\u001b[39;00m\n\u001b[1;32m    110\u001b[0m theme_models[theme] \u001b[38;5;241m=\u001b[39m (trained_model, train_losses, train_dataset, test_dataset)\n",
      "Cell \u001b[0;32mIn[23], line 21\u001b[0m, in \u001b[0;36mtrain_autoencoder\u001b[0;34m(model, train_loader, epochs, lr)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 反向传播\u001b[39;00m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/mmasd/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmasd/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmasd/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ========== 新增：训练/测试集划分配置 ==========\n",
    "TEST_SPLIT_RATIO = 0.2  # 8:2 划分训练/测试集\n",
    "RANDOM_STATE = 42  # 固定随机种子，确保划分结果可复现\n",
    "\n",
    "# ========== 批量训练所有Theme的自编码器（含训练/测试集划分）+ 训练集异常检测 ==========\n",
    "theme_models = {}  # {theme: (model, train_losses, train_dataset, test_dataset)}\n",
    "theme_anomaly_results = {}  # {theme: (train_frame_info_df, threshold, train_sample_stats)}\n",
    "\n",
    "for theme, full_dataset in theme_datasets.items():\n",
    "    print(f\"\\n\" + \"=\"*100)\n",
    "    print(f\"处理Theme：{theme}（含训练/测试集8:2划分）\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # -------------------------- 关键修改：划分训练/测试集 --------------------------\n",
    "    # 获取所有帧的索引，按Sample分组划分（避免同一Sample同时出现在训练/测试集）\n",
    "    all_sample_ids = full_dataset.frame_info_df['sample_idx'].unique()\n",
    "    # 按Sample划分训练/测试集（确保同一Sample的所有帧归为同一集合）\n",
    "    train_sample_ids, test_sample_ids = train_test_split(\n",
    "        all_sample_ids,\n",
    "        test_size=TEST_SPLIT_RATIO,\n",
    "        random_state=RANDOM_STATE,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # 筛选训练集数据（帧+元信息）\n",
    "    train_mask = full_dataset.frame_info_df['sample_idx'].isin(train_sample_ids)\n",
    "    train_frame_data = full_dataset.frame_data[train_mask]\n",
    "    train_frame_info_df = full_dataset.frame_info_df[train_mask].copy().reset_index(drop=True)\n",
    "    \n",
    "    # 筛选测试集数据（帧+元信息，仅保存，不参与训练）\n",
    "    test_mask = full_dataset.frame_info_df['sample_idx'].isin(test_sample_ids)\n",
    "    test_frame_data = full_dataset.frame_data[test_mask]\n",
    "    test_frame_info_df = full_dataset.frame_info_df[test_mask].copy().reset_index(drop=True)\n",
    "    \n",
    "    # 创建训练集Dataset（复用原有结构，仅包含训练集数据）\n",
    "    class TrainSubsetDataset(Dataset):\n",
    "        def __init__(self, frame_data, frame_info_df, mean, std):\n",
    "            self.frame_data = frame_data\n",
    "            self.frame_info_df = frame_info_df\n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "            self.sample_count = len(train_sample_ids)\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.frame_data)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            return torch.tensor(self.frame_data[idx], dtype=torch.float32)\n",
    "    \n",
    "    train_dataset = TrainSubsetDataset(\n",
    "        frame_data=train_frame_data,\n",
    "        frame_info_df=train_frame_info_df,\n",
    "        mean=full_dataset.mean,\n",
    "        std=full_dataset.std\n",
    "    )\n",
    "    \n",
    "    # 创建测试集Dataset（仅保存，供后续测试使用）\n",
    "    class TestSubsetDataset(Dataset):\n",
    "        def __init__(self, frame_data, frame_info_df, mean, std):\n",
    "            self.frame_data = frame_data\n",
    "            self.frame_info_df = frame_info_df\n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "            self.sample_count = len(test_sample_ids)\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.frame_data)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            return torch.tensor(self.frame_data[idx], dtype=torch.float32)\n",
    "    \n",
    "    test_dataset = TestSubsetDataset(\n",
    "        frame_data=test_frame_data,\n",
    "        frame_info_df=test_frame_info_df,\n",
    "        mean=full_dataset.mean,\n",
    "        std=full_dataset.std\n",
    "    )\n",
    "    \n",
    "    # 打印划分结果\n",
    "    print(f\"训练集：Sample数={len(train_sample_ids)} | 帧数={len(train_dataset)}\")\n",
    "    print(f\"测试集：Sample数={len(test_sample_ids)} | 帧数={len(test_dataset)}\")\n",
    "    print(f\"划分比例：训练集{1-TEST_SPLIT_RATIO:.0%} | 测试集{TEST_SPLIT_RATIO:.0%}\")\n",
    "    \n",
    "    # -------------------------- 原有训练逻辑（仅用训练集训练） --------------------------\n",
    "    # 创建训练集DataLoader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=min(4, os.cpu_count()),\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    # 初始化新模型（避免Theme间权重干扰）\n",
    "    model = FrameAutoencoder(\n",
    "        input_channels=input_channels,\n",
    "        num_joints=NUM_JOINTS,\n",
    "        hidden_dim=128\n",
    "    ).to(device)\n",
    "    \n",
    "    # 训练（仅用训练集）\n",
    "    trained_model, train_losses = train_autoencoder(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        epochs=EPOCHS,\n",
    "        lr=1e-4\n",
    "    )\n",
    "    \n",
    "    # -------------------------- 保存模型（新增测试集相关信息） --------------------------\n",
    "    theme_models[theme] = (trained_model, train_losses, train_dataset, test_dataset)\n",
    "    model_save_path = os.path.join(OUTPUT_DIR, f\"autoencoder_{theme}_{MODALITY}_with_split.pth\")\n",
    "    torch.save({\n",
    "        'theme': theme,\n",
    "        'modality': MODALITY,\n",
    "        'model_state_dict': trained_model.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'mean': full_dataset.mean,\n",
    "        'std': full_dataset.std,\n",
    "        'train_sample_ids': train_sample_ids.tolist(),\n",
    "        'test_sample_ids': test_sample_ids.tolist(),\n",
    "        'test_split_ratio': TEST_SPLIT_RATIO\n",
    "    }, model_save_path)\n",
    "    print(f\"模型保存路径：{model_save_path}（含训练/测试集划分信息）\")\n",
    "    \n",
    "    # -------------------------- 仅对训练集做异常检测（测试集留到单元2） --------------------------\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(f\"逐帧检测Theme：{theme}（仅训练集）的异常帧\")\n",
    "    print(\"=\"*80)\n",
    "    train_frame_info_df, threshold, train_sample_stats = detect_anomaly_frames_frame_level(\n",
    "        theme=theme,\n",
    "        model=trained_model,\n",
    "        dataset=train_dataset,  # 仅用训练集检测\n",
    "        threshold=ANOMALY_THRESHOLD\n",
    "    )\n",
    "    theme_anomaly_results[theme] = (train_frame_info_df, threshold, train_sample_stats)\n",
    "    \n",
    "    # 保存训练集结果\n",
    "    train_frame_info_df.to_csv(os.path.join(OUTPUT_DIR, f\"{theme}_train_frame_level_results.csv\"), index=False, encoding='utf-8-sig')\n",
    "    train_sample_stats.to_csv(os.path.join(OUTPUT_DIR, f\"{theme}_train_sample_anomaly_stats.csv\"), encoding='utf-8-sig')\n",
    "    train_anomaly_frames_df = train_frame_info_df[train_frame_info_df['is_anomaly']].copy()\n",
    "    train_anomaly_frames_df.to_csv(os.path.join(OUTPUT_DIR, f\"{theme}_train_anomaly_frames_detail.csv\"), index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"\\n训练集结果保存路径：\")\n",
    "    print(f\"  - 逐帧详细结果：{theme}_train_frame_level_results.csv\")\n",
    "    print(f\"  - Sample异常统计：{theme}_train_sample_anomaly_stats.csv\")\n",
    "    print(f\"  - 异常帧详情：{theme}_train_anomaly_frames_detail.csv\")\n",
    "    \n",
    "    # 保存测试集元信息（供单元2测试使用）\n",
    "    test_meta_save_path = os.path.join(OUTPUT_DIR, f\"{theme}_test_dataset_meta.csv\")\n",
    "    test_dataset.frame_info_df.to_csv(test_meta_save_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"  - 测试集元信息：{theme}_test_dataset_meta.csv（供后续测试使用）\")\n",
    "\n",
    "# -------------------------- 原有可视化训练损失逻辑 --------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "for theme, (_, losses, _, _) in theme_models.items():\n",
    "    plt.plot(range(1, EPOCHS+1), losses, label=theme, linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('重建损失（MSE）')\n",
    "plt.title(f'{MODALITY}模态 - 各Theme自编码器训练损失曲线（8:2划分训练/测试集）')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'train_losses_all_themes_with_split.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n\" + \"=\"*100)\n",
    "print(f\"所有Theme训练完成！\")\n",
    "print(f\"关键输出：\")\n",
    "print(f\"  1. 模型权重（含划分信息）：autoencoder_{theme}_{MODALITY}_with_split.pth\")\n",
    "print(f\"  2. 训练集异常检测结果：{theme}_train_*.csv\")\n",
    "print(f\"  3. 测试集元信息：{theme}_test_dataset_meta.csv\")\n",
    "print(f\"  4. 训练损失曲线：train_losses_all_themes_with_split.png\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOO5LM6QoKLbY8D7mtsxFJJ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mmasd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
